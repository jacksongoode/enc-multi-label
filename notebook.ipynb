{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitfa181860695c457eae5866062afe30fc",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal\n",
    "import os\n",
    "import sys \n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import csv\n",
    "from ast import literal_eval\n",
    "\n",
    "# External\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from pydub import AudioSegment, effects\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, multilabel_confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database generation with pydub (2 samples per file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = './UrbanSounds8K/audio/'\n",
    "dest_dir = './multi/' # new database is stored in multi folder next to original audio folder\n",
    "folds = np.array(['fold1','fold2','fold3','fold4',\n",
    "                  'fold5','fold6','fold7','fold8',\n",
    "                  'fold9','fold10'])\n",
    "\n",
    "multi_num = 2 # number of overlayed files\n",
    "files = [0] * multi_num\n",
    "labels = [0] * multi_num\n",
    "samples = [0] * multi_num\n",
    "sounds = [0] * multi_num\n",
    "names = [0] * multi_num\n",
    "mult_dict = {}\n",
    "redo = False\n",
    "\n",
    "for fold in folds:\n",
    "    fold_files = os.listdir(source_dir+fold)\n",
    "    fold_files = [f for f in fold_files if f.endswith('.wav')]\n",
    "    random.shuffle(fold_files)\n",
    "    print(f'On fold: {fold}')\n",
    "    len(fold_files)\n",
    "\n",
    "    while len(fold_files) > 1:\n",
    "        rand_gain = [random.randint(-6,0) for _ in range(multi_num)]\n",
    "        p_ratio = [0] * multi_num\n",
    "\n",
    "        for j in range(multi_num):\n",
    "            try:\n",
    "                samples[j] = fold_files[j]\n",
    "                sounds[j] = AudioSegment.from_file(f'{source_dir}{fold}/{samples[j]}')\n",
    "            except:\n",
    "                fold_files.remove(fold_files[j]) # remove file from list unable to load - prevents unused files when 1st loads and 2nd fails\n",
    "                redo = True \n",
    "                break\n",
    "\n",
    "        if redo is True:\n",
    "            print('Unable to read file...')\n",
    "            redo = False # reset\n",
    "            continue # back to iter of last successful load\n",
    "        else:\n",
    "            del fold_files[0:multi_num] # pop loaded files off top\n",
    "        \n",
    "        for j in range(multi_num): # go through again to mix\n",
    "            print(f'Processing: {samples[j]}')\n",
    "            labels[j] = samples[j].split('-')[1] # get label\n",
    "            sounds[j] = effects.normalize(sounds[j]) # normalize\n",
    "            sounds[j] = sounds[j] + rand_gain[j] # add random gain reduction\n",
    "            p_ratio[j] = pow(10, rand_gain[j]/10) # convert to power\n",
    "            names[j] = f'-{labels[j]}({round(p_ratio[j],2)})'\n",
    "\n",
    "        combined = []\n",
    "        combined.append(sounds[0].overlay(sounds[1], times=20)) # overlay sound (with repeat if base sound is longer)\n",
    "        \n",
    "        # this would be used to further overlay strings but here we only use 2 sounds so no use\n",
    "        # for j in range(multi_num - 1):\n",
    "            # combined.append(combined[j].overlay(sounds[j+2], times=20))\n",
    "\n",
    "        name_info = ''.join(names)\n",
    "        fn = f'{dest_dir}{fold}/comb{name_info}.wav' # create unique filename with label\n",
    "        combined[-1].export(fn, format=\"wav\")\n",
    "\n",
    "        full_label = []\n",
    "        for j in range(multi_num):\n",
    "            full_label.append((labels[j], p_ratio[j]))\n",
    "        mult_dict[fn] = full_label\n",
    "\n",
    "# Save new database labels as csv\n",
    "df = pd.DataFrame.from_dict(mult_dict, orient=\"index\")\n",
    "df.to_csv(f\"{dest_dir}multi-labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_dur = './multi'\n",
    "\n",
    "# Load label csv as dict\n",
    "reader = csv.reader(open(f'{dest_dur}/multi-labels.csv'))\n",
    "multi_dict = {}\n",
    "for column in reader:\n",
    "    key = column[0]\n",
    "    if key in multi_dict:\n",
    "        pass\n",
    "    multi_dict[key] = column[1:]\n",
    "\n",
    "### Extract features for multi-category ###\n",
    "def extract_features_multi(parent_dir,sub_dir,file_ext=\"*.wav\",\n",
    "                     bands=60,frames=41):\n",
    "    def _windows(data, window_size):\n",
    "        start = 0\n",
    "        while start < len(data):\n",
    "            yield int(start), int(start + window_size)\n",
    "            start += (window_size // 2)\n",
    "            \n",
    "    window_size = 512 * (frames - 1) # size of sliding window for taking multiple samples of each sound, could be extended\n",
    "    features, labels = [], []\n",
    "    for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "        segment_log_specgrams, segment_labels = [], []\n",
    "        sound_clip, xsr = librosa.load(fn)\n",
    "        print('Processing: %s' % fn)\n",
    "        try:\n",
    "            label = multi_dict[fn] # label\n",
    "            label = [int(literal_eval(point)[0]) for point in label] # add labels (multi categories) ex. [1,2]\n",
    "        except KeyError: # if the sample is not in the database, ie. unseen\n",
    "            label = None\n",
    "        \n",
    "        # Extract features per window/segment\n",
    "        for (start,end) in _windows(sound_clip,window_size):\n",
    "            if(len(sound_clip[start:end]) == window_size):\n",
    "                signal = sound_clip[start:end]\n",
    "                melspec = librosa.feature.melspectrogram(signal,n_mels=bands) # extracting melspec with 60 bands\n",
    "                # spec = librosa.feature.spectrogram(signal, n_mels=bans) # may be interest in testing performance of spectrogram\n",
    "                logspec = librosa.amplitude_to_db(melspec)  # converting to log scale\n",
    "                logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "                segment_log_specgrams.append(logspec)\n",
    "                segment_labels.append(label)\n",
    "            \n",
    "        segment_log_specgrams = np.asarray(segment_log_specgrams).reshape(\n",
    "            len(segment_log_specgrams),bands,frames,1) # reshape to (60, 41, 1)\n",
    "        segment_features = np.concatenate((segment_log_specgrams, np.zeros(\n",
    "            np.shape(segment_log_specgrams))), axis=3) # add one layer to axis -> (60, 40, 2)\n",
    "        for i in range(len(segment_features)): \n",
    "            segment_features[i, :, :, 1] = librosa.feature.delta(\n",
    "                segment_features[i, :, :, 0]) # extract deltas into new layer\n",
    "        \n",
    "        if len(segment_features) > 0: # check for empty segments \n",
    "            features.append(segment_features)\n",
    "            labels.append(segment_labels)\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features into file (per fold and full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Pre-process and extract feature from the data (per fold)\n",
    "parent_dir = './multi'\n",
    "feat_dir = \"./multi-processed\"\n",
    "folds = sub_dirs = np.array(['fold1','fold2','fold3','fold4',\n",
    "                  'fold5','fold6','fold7','fold8',\n",
    "                  'fold9','fold10'])\n",
    "\n",
    "for fold in folds:\n",
    "    print(f'Now in: {fold}')\n",
    "    features, labels = extract_features_multi(parent_dir,fold)\n",
    "    np.savez(f'{feat_dir}/{fold}', features=features, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create single file for full dataset through appending - quick)\n",
    "feat_dir = \"./multi-processed\"\n",
    "folds = sub_dirs = np.array(['fold1','fold2','fold3','fold4',\n",
    "                  'fold5','fold6','fold7','fold8',\n",
    "                  'fold9','fold10'])\n",
    "full_features = []\n",
    "full_labels = []\n",
    "\n",
    "for fold in folds:\n",
    "    data = np.load(f'{feat_dir}/{fold}.npz', allow_pickle=True)\n",
    "    features = data[\"features\"]\n",
    "    labels = data[\"labels\"]\n",
    "    full_features.append(features)\n",
    "    full_labels.append(labels)\n",
    "    \n",
    "np.savez(f'{feat_dir}/full_features', features=full_features, labels=full_labels) # combined and saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define architecture of CNN with Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_multi():\n",
    "    num_filters = [24, 32, 64, 128] \n",
    "    pool_size = (2, 2) \n",
    "    kernel_size = (3, 3) \n",
    "    input_shape = (60, 41, 2) # two layers for melspec and deltas of melspec\n",
    "    num_classes = 10 # categories of sound\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(24, kernel_size,\n",
    "                padding=\"same\", input_shape=input_shape))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"relu\"))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(32, kernel_size,\n",
    "                                  padding=\"same\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"relu\"))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(64, kernel_size,\n",
    "                                  padding=\"same\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"relu\")) \n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(128, kernel_size,\n",
    "                                  padding=\"same\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"relu\"))  \n",
    "\n",
    "    model.add(keras.layers.GlobalMaxPooling2D())\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(num_classes, activation='sigmoid')) # sigmoid provides unconstrained probability distrib vs softmax\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-4), \n",
    "        loss='binary_crossentropy', # one-hot encoding for binary arrays\n",
    "        metrics=[\"categorical_accuracy\"]) # provides better estimates of accuracy for one-hot labels\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cp_path = \"./models/checkpoint.hdf5\"\n",
    "checkpoint = ModelCheckpoint(cp_path, monitor='loss', verbose=1, save_best_only=True,\n",
    "                            mode='auto', save_freq='epoch')\n",
    "load_dir = \"./multi-processed\"\n",
    "\n",
    "data = np.load(\"{0}/{1}.npz\".format(load_dir,'full_features'),\n",
    "                allow_pickle=True)\n",
    "\n",
    "features = np.concatenate(data[\"features\"], axis = 0)\n",
    "labels = np.concatenate(data[\"labels\"], axis = 0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=.2, callbacks=[checkpoint])\n",
    "\n",
    "x_train = np.concatenate(x_train, axis = 0).astype(np.float32)\n",
    "y_train = np.concatenate(y_train, axis = 0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode labels as one-hot binary arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]) # fit mlb to the category range\n",
    "\n",
    "y_tr_array = np.array(y_train)\n",
    "y_tr_hot = mlb.transform(y_tr_array) # this can be done because multi ones-hot arrays are not needed (as they are when comparing test to predict)\n",
    "\n",
    "y_te_hot = []\n",
    "for y in y_test: # for each window sample of one sound file in test set\n",
    "    y_te_array = np.array(y)\n",
    "    y_hot = mlb.transform(y_te_array) # encoding with transform\n",
    "    y_te_hot.append(y_hot)\n",
    "y_te_hot = np.array(y_te_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and model for 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of epochs and batch size can be adjusted for an individual workstation\n",
    "\n",
    "model = get_network_multi()\n",
    "# model.load_weights(cp_path) # if interuption possible - load weights from last point, comment above line\n",
    "\n",
    "history = model.fit(x_train, y_tr_hot, epochs = 30, batch_size = 48, verbose = 1)\n",
    "\n",
    "# model.save('./models/models-%s' % time.time())\n",
    "model.save('./models/models-multi-%s' % time.time()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained model for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./models/models-multi-1600424459.55954')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model performance with performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true, y_pred = [], []\n",
    "\n",
    "print('Evaluating on test set...')\n",
    "for x, y in zip(x_test, y_te_hot):\n",
    "    # average predictions over segments of a sound clip\n",
    "    pred = model.predict(x)\n",
    "    avg_p = np.unique(np.argmax(pred, axis=1)) # avg predictions of each array\n",
    "    hot_p = mlb.transform([avg_p]) # convert to one-hot encoding - no idea why it wont pass without brackets \n",
    "\n",
    "    # print(f'Predict: {hot_p}')\n",
    "    y_pred.append(hot_p[0]) \n",
    "    \n",
    "    # print(f'True: {y[0]}') \n",
    "    y_true.append(y[0]) # pick single label for a sound clip (they're all identical)\n",
    "\n",
    "hamming = hamming_loss(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "     \n",
    "print(f'Average Accuracy: {accuracy}')\n",
    "print(f'Average Hamming: {hamming}\\n')\n",
    "print(f'{multilabel_confusion_matrix(y_true, y_pred)}\\n')\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_dir = './'\n",
    "sub_dir = 'testing' # directory for unseen samples\n",
    "test_files = [fn for fn in os.listdir(parent_dir+sub_dir) if fn.endswith('.wav')]\n",
    "\n",
    "look_up = [\n",
    "    \"air_conditioner\",  # 0\n",
    "    \"car_horn\",         # 1\n",
    "    \"children_playing\", # 2\n",
    "    \"dog_bark\",         # 3\n",
    "    \"drilling\",         # 4\n",
    "    \"engine_idling\",    # 5\n",
    "    \"gun_shot\",         # 6\n",
    "    \"jackhammer\",       # 7\n",
    "    \"siren\",            # 8\n",
    "    \"street_music\"      # 9\n",
    "    ]\n",
    "\n",
    "print('\\nPredicting!')\n",
    "features, labels = extract_features_multi(parent_dir, sub_dir)\n",
    "\n",
    "predictions = []\n",
    "for x in features:\n",
    "    pred = model.predict(x)\n",
    "    avg_p = np.unique(np.argmax(pred, axis=1))\n",
    "    predictions.append(avg_p)\n",
    "\n",
    "print('\\nPredictions')\n",
    "for fn, pred in zip(test_files, predictions):\n",
    "    print(f'File: {fn} -> Prediction category: {pred}')\n",
    "    [print(look_up[i]) for i in pred]"
   ]
  }
 ]
}